{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrSwoZ58C0kA",
        "outputId": "8f5573f8-beef-497b-e0e0-b0c5a5393afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neattext\n",
            "  Downloading neattext-0.1.3-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading neattext-0.1.3-py3-none-any.whl (114 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/114.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: neattext\n",
            "Successfully installed neattext-0.1.3\n"
          ]
        }
      ],
      "source": [
        "pip install neattext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import neattext as nt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import joblib"
      ],
      "metadata": {
        "id": "zDpuNBIpC6B7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('emotions_dataset.csv')\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVAcmjJOC6MW",
        "outputId": "f75b58c4-04e7-4772-aaf6-219f27c1eb57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             text    emotion\n",
            "0                 I feel awesome!      happy\n",
            "1               That's repulsive.  disgusted\n",
            "2             This is unexpected.  surprised\n",
            "3  Nothing exciting is happening.    neutral\n",
            "4       I am on top of the world!      happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the text column using NeatText\n",
        "df['clean_text'] = df['text'].apply(lambda x: nt.remove_stopwords(nt.remove_special_characters(x)).lower())\n",
        "\n",
        "print(df[['text', 'clean_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9uO-wdKC6O7",
        "outputId": "b1018c92-b1bd-4e75-cb4d-2a28765ad8e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             text          clean_text\n",
            "0                 I feel awesome!        feel awesome\n",
            "1               That's repulsive.     thats repulsive\n",
            "2             This is unexpected.          unexpected\n",
            "3  Nothing exciting is happening.  exciting happening\n",
            "4       I am on top of the world!               world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=10000)  # Limit to the top 10,000 words\n",
        "tokenizer.fit_on_texts(df['clean_text'])\n",
        "\n",
        "# Converting the text into sequences\n",
        "X = tokenizer.texts_to_sequences(df['clean_text'])\n",
        "\n",
        "# Padding sequences to ensure uniform input size\n",
        "X = pad_sequences(X, padding='post')"
      ],
      "metadata": {
        "id": "ByrkdokdC6Rc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the labels i.e emotions\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['emotion'])"
      ],
      "metadata": {
        "id": "0MUq2T2QC6Ty"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "I4OJcgTZC6WE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the BiLSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Adding an Embedding layer\n",
        "model.add(Embedding(input_dim=10000, output_dim=128, input_length=X_train.shape[1]))\n",
        "\n",
        "# Adding a Bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "\n",
        "# Dropout layer for regularization\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Another LSTM layer\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "\n",
        "# Dense output layer with softmax activation for multi-class classification\n",
        "model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compiling the model with adam optimizer and sparse categorical crossentropy for predictions\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "x8G4e03VC6Yf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kvfenLfC6as",
        "outputId": "e30c7b38-8227-4e2c-f8e7-974e89a188c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 9ms/step - accuracy: 0.9284 - loss: 0.2036 - val_accuracy: 0.9769 - val_loss: 0.0323\n",
            "Epoch 2/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.9756 - loss: 0.0343 - val_accuracy: 0.9766 - val_loss: 0.0326\n",
            "Epoch 3/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9753 - loss: 0.0340 - val_accuracy: 0.9766 - val_loss: 0.0324\n",
            "Epoch 4/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9747 - loss: 0.0343 - val_accuracy: 0.9766 - val_loss: 0.0324\n",
            "Epoch 5/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - accuracy: 0.9756 - loss: 0.0340 - val_accuracy: 0.9769 - val_loss: 0.0322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V7D8XlcC6dJ",
        "outputId": "e4d7fb7e-71e6-4553-80ec-386c37edc49a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.0321\n",
            "Test Accuracy: 97.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('emotion_bilstm_model.h5')\n",
        "joblib.dump(tokenizer, 'text_tokenizer.pkl')\n",
        "joblib.dump(encoder, 'label_encoder.pkl')\n",
        "\n",
        "print(\"Model, tokenizer and encoder saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJX9yDC9C6gl",
        "outputId": "40f02b35-8962-4fef-cc65-a57d816bfe7e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model, tokenizer and encoder saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion_from_input():\n",
        "    new_text = input(\"Enter a sentence to predict emotion: \")\n",
        "\n",
        "    cleaned_text = nt.remove_stopwords(nt.remove_special_characters(new_text)).lower()\n",
        "\n",
        "    X_new = tokenizer.texts_to_sequences([cleaned_text])\n",
        "\n",
        "    X_new_pad = pad_sequences(X_new, padding='post', maxlen=X_train.shape[1])\n",
        "\n",
        "    emotion_pred = model.predict(X_new_pad)\n",
        "    predicted_emotion = encoder.inverse_transform([np.argmax(emotion_pred)])\n",
        "\n",
        "    print(f\"The emotion of the text is: {predicted_emotion[0]}\")"
      ],
      "metadata": {
        "id": "zyHUa9WgMB2c"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_emotion_from_input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8maxWdXMTcj",
        "outputId": "462aae7e-6591-474c-9eff-0d0ec9fb0293"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to predict emotion: the movie was amazing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
            "The emotion of the text is: happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_emotion_from_input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSJiqJS0SuNO",
        "outputId": "2cde1f6e-2ee7-4334-f904-b87de3e69112"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to predict emotion: i want to make this but i am unsure about it\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "The emotion of the text is: fearful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_emotion_from_input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1lzkeSQS-v1",
        "outputId": "84ab846c-e12c-4293-f615-f0163445f8a9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to predict emotion: I can't believe this is happening, it's so unbelievable and shocking! What a surprise!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "The emotion of the text is: surprised\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_emotion_from_input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiDu27gHTA2t",
        "outputId": "0a2dabed-b5d8-47e8-cd18-2b0b93db4c1d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to predict emotion: This is terrible, I can't stop crying. Everything seems so hopeless\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "The emotion of the text is: sad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_emotion_from_input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjNsd0zaTon4",
        "outputId": "2c4bf6ff-a0f2-4441-abbc-4acebc131954"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to predict emotion: Nothing exciting or bad is happening.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "The emotion of the text is: neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_emotion_from_input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdT0W5LYT6hS",
        "outputId": "0a55b5eb-b881-46d0-d916-b76094e21823"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to predict emotion: I can't stand this smell.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "The emotion of the text is: disgusted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_emotion_from_input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcwoamvNUT8F",
        "outputId": "01ae380e-75da-4707-9a9e-95080303219e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to predict emotion: I am really scared about the upcoming exam. I feel anxious and overwhelmed\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "The emotion of the text is: fearful\n"
          ]
        }
      ]
    }
  ]
}